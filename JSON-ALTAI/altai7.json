{
    "id": "1670175625",
    "title": "Accountability",
    "desc": "The principle of accountability necessitates that mechanisms be put in place to ensure responsibility for the development, deployment and/or use of AI systems. This topic is closely related to risk management, identifying and mitigating risks in a transparent way that can be explained to and audited by third parties. When unjust or adverse impacts occur, accessible mechanisms for accountability should be in place that ensure an adequate possibility of redress.",
    "sections": [
        {
            "id": "1670175634",
            "title": "Auditability",
            "desc": "This subsection helps to self-assess the existing or necessary level that would be required for an evaluation of the AI system by internal and external auditors. The possibility to conduct evaluations as well as to access records on said evaluations can contribute to Trustworthy AI. In applications affecting fundamental rights, including safety-critical applications, AI systems should be able to be independently audited. This does not necessarily imply that information about business models and intellectual property related to the AI system must always be openly available."
        },
        {
            "id": "1670175641",
            "title": "Risk Management",
            "desc": "Both the ability to report on actions or decisions that contribute to the AI system's outcome, and to respond to the consequences of such an outcome, must be ensured. Identifying, assessing, documenting and minimising the potential negative impacts of AI systems is especially crucial for those (in)directly affected. Due protection must be available for whistle-blowers, NGOs, trade unions or other entities when reporting legitimate concerns about an AI system. When implementing the above requirements, tensions may arise between them, which may lead to inevitable trade- offs.Such trade - offs should be addressed in a rational and methodological manner within the state of the art.This entails that relevant interests and values implicated by the AI system should be identified and that, if conflict arises, trade- offs should be explicitly acknowledged and evaluated in terms of their risk to safety and ethical principles, including fundamental rights.Any decision about which trade - off to make should be well reasoned and properly documented.When adverse impact occurs, accessible mechanisms should be foreseen that ensure adequate redress."
        }
    ],
    "cards": [
        {
            "id": "1670175654",
            "title": "rate the measures in place to ensure the auditability of the =gb=AI system",
            "example" : [
                {
                    "title": "AI GPT3 generated example",
                    "desc"  : "What potential risks exist for human autonomy if an AI system is implemented?"
                }
            ],
            "desc": "The following questions will help you in your evaluation",
            "section": "1670175634",
            "questions": [
                {
                    "id": "AC-Q1-B",
                    "title": "Did you establish mechanisms that facilitate the =gb=AI system=ge=’s auditability (e.g. traceability of the development process, the sourcing of training data and the logging of the AI system’s processes, outcomes, positive and negative impact)? =hb=Auditability entails the enablement of the assessment of algorithms, data and design processes. This does not necessarily imply that information about business models and intellectual property related to the AI system must always be openly available. =br=EGTAI p. 19-20.=he=",
                    "type": "radiogroup",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q2-B",
                    "visibleIf": "",
                    "title": "Did you ensure that the =gb=AI system=ge= can be audited by independent third parties? =hb=Evaluation by internal and external auditors, and the availability of such evaluation reports, can contribute to the trustworthiness of the technology. In applications affecting fundamental rights, including safety-critical applications, AI systems should be able to be independently audited. <br/>EGTAI p. 20=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-S1-R",
                    "visibleIf": "",
                    "title": "Based on the answer you gave above, do you believe the measures in place to ensure the auditability of the =gb=AI system=ge= are:=hb=Auditability entails the enablement of the assessment of algorithms, data and design processes.<br/> EGTAI p. 19=he=",
                    "isScored": 1,
                    "colCount": "5",
                    "answers": [
                        "Non-existent", "Completely Inadequate", "Almost adequate", "Adequate", "Fully adequate"
                    ]
                }
            ]
        },
        {
            "id": "1670175662",
            "title": "Rate the risk management system you have in place.",
            "example" : [
                {
                    "title": "AI GPT3 generated example",
                    "desc"  : "What potential risks exist for human autonomy if an AI system is implemented?"
                }
            ],
            "desc": "The following questions will help you in your evaluation",
            "section": "1670175641",
            "questions": [
                {
                    "type": "radiogroup",
                    "id": "AC-Q3-B",
                    "title": "Did you foresee any kind of external guidance or third-party auditing processes to oversee ethical concerns and accountability measures?  =hb=Evaluation by internal and external auditors, and the availability of such evaluation reports, can contribute to the trustworthiness of the technology. In applications affecting fundamental rights, or cause adverse impacts to individuals, society and the environment. AI systems should be able to be independently audited. <br/>EGTAI p. 20=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q31-B",
                    "visibleIf": "",
                    "title": "Does the involvement of these third parties go beyond the development phase?  =hb=In order to achieve Trustworthy AI, we must enable inclusion and diversity throughout the entire AI system’s life cycle. Besides the consideration and involvement of all affected stakeholders throughout the process, this also entails ensuring equal access through inclusive design processes as well as equal treatment. <br/>EGTAI p. 18=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q4-B",
                    "visibleIf": "",
                    "title": "Did you organise risk training and, if so, does this also inform about the potential legal framework applicable to the =gb=AI system=ge=? =hb= It must be ensured that the system will do what it is supposed to do without harming individuals, society and the environment. This includes the minimisation of unintended consequences and errors. In addition, processes to clarify and assess potential risks associated with the use of AI systems, across various application areas, should be established. <br/>EGTAI p. 17=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q5-B",
                    "visibleIf": "",
                    "title": "Did you consider establishing an ‘AI ethics review board’ or a similar mechanism to discuss the overall =gb=accountability=ge= and ethics practices, including potential unclear grey areas? =hb=In order to develop AI systems that are trustworthy, it is advisable to consult stakeholders who may directly or indirectly be affected by the system throughout its life cycle. It is beneficial to solicit regular feedback even after deployment and set up longer term mechanisms for stakeholder participation, for example by ensuring workers information, consultation and participation throughout the whole process of implementing AI systems at organisations. <br/>EGTAI p. 19=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q6-B",
                    "visibleIf": "",
                    "title": "Did you establish a mechanism to identify conflicts of values that could be implemented in your =gb=AI system=ge= and your own interests? ",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q6.1-B",
                    "visibleIf": "",
                    "title": "Does this process include identification and documentation of trade-offs between different ethical principles? =hb=Tensions may arise between ethical principles, for which there is no fixed solution. In line with the EU fundamental commitment to democratic engagement, due process and open political participation, methods of accountable deliberation to deal with such tensions should be established. <br/>EGTAI p.14=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q6.2-B",
                    "visibleIf": "",
                    "title": "How did you decide on such trade-offs? Did you ensure that the trade-off decision was documented?=hb= AI systems’ overall benefits should substantially exceed the foreseeable individual risks. AI practitioners can hence not be expected to find the right solution based on the principles above, yet they should approach ethical dilemmas and trade-offs via reasoned, evidence-based reflection rather than intuition or random discretion. =he=",
                    "isScored": 0,
                    "answers": [
                        "Yes",  "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q7-B",
                    "visibleIf": "",
                    "title": "Did you establish a processes for third parties (e.g. suppliers, =gb=end-users=ge=, =gb=subjects=ge=, distributors/vendors or workers) or workers to report potential vulnerabilities, risks or biases in the =gb=AI system=ge=?=hb=In order to develop AI systems that are trustworthy, it is advisable to consult stakeholders who may directly or indirectly be affected by the system throughout its lifecycle. It is beneficial to solicit regular feedback even after deployment and set up longer term mechanisms for stakeholder participation, for example by ensuring workers information, consultation and participation throughout the whole process of implementing AI systems at organisations. <br/> EGTAI p. 19=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q8-B",
                    "visibleIf": "",
                    "title": "Does this process foster revision of the risk management process?=hb=It is beneficial to solicit regular feedback even after deployment and set up longer term mechanisms for stakeholder participation, for example by ensuring workers information, consultation and participation throughout the whole process of implementing AI systems at organisations. <br/> EGTAI p. 19=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", "Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-Q9-B",
                    "visibleIf": "",
                    "title": " For applications that can significantly adversely affect individuals, have =gb=redress by design=ge= mechanisms been put in place?=hb=When unjust adverse impact occurs, accessible mechanisms should be foreseen that ensure adequate, accessible and effective redress. <br/>EGTAI p. 20 <br/>=he=",
                    "isScored": 0,
                    "answers": [
                        "Yes", "No", " Don't know"
                    ]
                }, {
                    "type": "radiogroup",
                    "id": "AC-S2-R",
                    "visibleIf": "",
                    "title": "Based on the answer you gave above, do you believe the risk management system you have in place is:",
                    "isScored": 1,
                    "colCount": "5",
                    "answers": [
                        "Non-existent", "Completely Inadequate", "Almost adequate", "Adequate", "Fully adequate"
                    ]
                }
            ]
        }
    ]
}